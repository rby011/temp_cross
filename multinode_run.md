두 노드 모두 **동일한 스크립트 sft_vlm.py**를 실행하되, Accelerate 설정 파일(yaml)만 다르게 (혹은 명령줄 인자 override 방식으로) 설정
--model_name_or_path, --dataset_name 등 다른 학습 파라미터는 동일하게 맞춰야 합니다(서로 다른 모델, 다른 데이터셋으로 학습하면 안 됨)

노드 간 파일 공유
분산 학습 시, 동일한 데이터셋이 모든 노드에 존재해야 하거나(일반적으로), 혹은 각 노드에서 자체적으로 데이터를 로드할 수 있도록 설정
파일 시스템(NFS, 공유 디스크 등)을 사용하는 방법이나, 노드별로 동일 경로에 사전 다운로드된 데이터셋을 배치하는 방식

Python 환경 통일
두 노드에서 사용하는 PyTorch/Accelerate/DeepSpeed/Transformers/TRL 등 라이브러리 버전 동일 
CUDA, 드라이버 버전 호환성도 체크

성능 이슈
노드당 GPU 개수가 다르면, 한쪽이 8개, 다른 쪽이 2개로 균형이 맞지 않아 학습 속도나 통신량 측면에서 성능이 비대칭

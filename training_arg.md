| **argument**                                         | **type**                                                   | **optional?** | **default** | **description**                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
|-------------------------------------------------------|------------------------------------------------------------|--------------:|------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **output_dir**                                        | `str`                                                      | No           | -          | The output directory where the model predictions and checkpoints will be written.                                                                                                                                                                                                                                                                                                                                                                             |
| **overwrite_output_dir**                              | `bool`                                                     | Yes          | `False`    | If `True`, overwrite the content of the output directory. Use this to continue training if `output_dir` points to a checkpoint directory.                                                                                                                                                                                                                                                                                                                     |
| **do_train**                                          | `bool`                                                     | Yes          | `False`    | Whether to run training or not. This argument is not directly used by `Trainer`, it's intended for your training scripts.                                                                                                                                                                                                                                                                                                                                     |
| **do_eval**                                           | `bool`                                                     | Yes          | `False`    | Whether to run evaluation on the validation set or not. Will be set to `True` if `eval_strategy` is not `"no"`. Not directly used by `Trainer`.                                                                                                                                                                                                                                                                                                               |
| **do_predict**                                        | `bool`                                                     | Yes          | `False`    | Whether to run predictions on the test set or not. Not directly used by `Trainer`.                                                                                                                                                                                                                                                                                                                                                                             |
| **eval_strategy**                                     | `str` or `IntervalStrategy`                                | Yes          | `"no"`     | The evaluation strategy to adopt during training. Possible values are `"no"`, `"steps"`, `"epoch"`.                                                                                                                                                                                                                                                                                                                                                           |
| **prediction_loss_only**                              | `bool`                                                     | Yes          | `False`    | When performing evaluation and generating predictions, only returns the loss.                                                                                                                                                                                                                                                                                                                                                                                |
| **per_device_train_batch_size**                       | `int`                                                      | Yes          | `8`        | The batch size per GPU/XPU/TPU/MPS/NPU core/CPU for training.                                                                                                                                                                                                                                                                                                                                                                                                 |
| **per_device_eval_batch_size**                        | `int`                                                      | Yes          | `8`        | The batch size per GPU/XPU/TPU/MPS/NPU core/CPU for evaluation.                                                                                                                                                                                                                                                                                                                                                                                                |
| **gradient_accumulation_steps**                       | `int`                                                      | Yes          | `1`        | Number of update steps to accumulate the gradients for, before performing a backward/update pass.                                                                                                                                                                                                                                                                                                                                                             |
| **eval_accumulation_steps**                           | `int`                                                      | Yes          | -          | Number of prediction steps to accumulate output tensors for, before moving the results to CPU.                                                                                                                                                                                                                                                                                                                                                                |
| **eval_delay**                                        | `float`                                                    | Yes          | -          | Number of epochs or steps to wait for before the first evaluation can be performed (depending on `eval_strategy`).                                                                                                                                                                                                                                                                                                                                            |
| **torch_empty_cache_steps**                           | `int`                                                      | Yes          | -          | Number of steps to wait before calling `torch.<device>.empty_cache()`. Helpful for lowering VRAM usage at cost of slower performance.                                                                                                                                                                                                                                                                                                                          |
| **learning_rate**                                     | `float`                                                    | Yes          | `5e-5`     | The initial learning rate for the `AdamW` optimizer.                                                                                                                                                                                                                                                                                                                                                                                                           |
| **weight_decay**                                      | `float`                                                    | Yes          | `0`        | The weight decay to apply in `AdamW` (except bias and LayerNorm weights).                                                                                                                                                                                                                                                                                                                                                                                     |
| **adam_beta1**                                        | `float`                                                    | Yes          | `0.9`      | The beta1 hyperparameter for the `AdamW` optimizer.                                                                                                                                                                                                                                                                                                                                                                                                            |
| **adam_beta2**                                        | `float`                                                    | Yes          | `0.999`    | The beta2 hyperparameter for the `AdamW` optimizer.                                                                                                                                                                                                                                                                                                                                                                                                            |
| **adam_epsilon**                                      | `float`                                                    | Yes          | `1e-8`     | The epsilon hyperparameter for the `AdamW` optimizer.                                                                                                                                                                                                                                                                                                                                                                                                          |
| **max_grad_norm**                                     | `float`                                                    | Yes          | `1.0`      | Maximum gradient norm (for gradient clipping).                                                                                                                                                                                                                                                                                                                                                                                                                 |
| **num_train_epochs**                                  | `float`                                                    | Yes          | `3.0`      | Total number of training epochs to perform. If not an integer, will train the decimal part percent of the last epoch.                                                                                                                                                                                                                                                                                                                                          |
| **max_steps**                                         | `int`                                                      | Yes          | `-1`       | If set to a positive number, the total number of training steps to perform. Overrides `num_train_epochs`.                                                                                                                                                                                                                                                                                                                                                      |
| **lr_scheduler_type**                                 | `str` or `SchedulerType`                                   | Yes          | `"linear"` | The scheduler type to use (e.g. `"linear"`, `"cosine"`, `"constant"`, etc.).                                                                                                                                                                                                                                                                                                                                                                                   |
| **lr_scheduler_kwargs**                               | `dict`                                                     | Yes          | `{}`       | Extra arguments for the learning rate scheduler.                                                                                                                                                                                                                                                                                                                                                                                                               |
| **warmup_ratio**                                      | `float`                                                    | Yes          | `0.0`      | Ratio of total training steps for linear warmup from 0 to `learning_rate`.                                                                                                                                                                                                                                                                                                                                                                                     |
| **warmup_steps**                                      | `int`                                                      | Yes          | `0`        | Number of steps for linear warmup from 0 to `learning_rate`. Overrides any effect of `warmup_ratio`.                                                                                                                                                                                                                                                                                                                                                           |
| **log_level**                                         | `str`                                                      | Yes          | `"passive"`| Logger log level on the main process. Can be `'debug'`, `'info'`, `'warning'`, `'error'`, `'critical'`, or `'passive'`.                                                                                                                                                                                                                                                                                                                                        |
| **log_level_replica**                                 | `str`                                                      | Yes          | `"warning"`| Logger log level on replicas. Same choices as `log_level`.                                                                                                                                                                                                                                                                                                                                                                                                     |
| **log_on_each_node**                                  | `bool`                                                     | Yes          | `True`     | In multi-node distributed training, whether to log once per node using `log_level`.                                                                                                                                                                                                                                                                                                                                                                            |
| **logging_dir**                                       | `str`                                                      | Yes          | -          | TensorBoard log directory. Defaults to `output_dir/runs/CURRENT_DATETIME_HOSTNAME`.                                                                                                                                                                                                                                                                                                                                                                            |
| **logging_strategy**                                  | `str` or `IntervalStrategy`                                | Yes          | `"steps"`  | The logging strategy to adopt during training: `"no"`, `"epoch"`, or `"steps"`.                                                                                                                                                                                                                                                                                                                                                                               |
| **logging_first_step**                                | `bool`                                                     | Yes          | `False`    | Whether to log the first `global_step` or not.                                                                                                                                                                                                                                                                                                                                                                                                                 |
| **logging_steps**                                     | `int` or `float`                                           | Yes          | `500`      | Number of update steps between logs if `logging_strategy="steps"`. Can be float < 1.0 for ratio of total steps.                                                                                                                                                                                                                                                                                                                                                |
| **logging_nan_inf_filter**                            | `bool`                                                     | Yes          | `True`     | Whether to filter `nan` and `inf` losses for logging, replacing them with average loss of the current window.                                                                                                                                                                                                                                                                                                                                                 |
| **save_strategy**                                     | `str` or `SaveStrategy`                                    | Yes          | `"steps"`  | The checkpoint save strategy: `"no"`, `"epoch"`, `"steps"`, or `"best"`.                                                                                                                                                                                                                                                                                                                                                                                       |
| **save_steps**                                        | `int` or `float`                                           | Yes          | `500`      | Number of steps between checkpoints if `save_strategy="steps"`. Can be float < 1.0 for ratio of total steps.                                                                                                                                                                                                                                                                                                                                                   |
| **save_total_limit**                                  | `int`                                                      | Yes          | -          | If set, limits the total amount of checkpoints. Older checkpoints are deleted. Special handling if `load_best_model_at_end` is True.                                                                                                                                                                                                                                                                                                                           |
| **save_safetensors**                                  | `bool`                                                     | Yes          | `True`     | Use `safetensors` saving/loading for state dicts instead of `torch.load`/`torch.save`.                                                                                                                                                                                                                                                                                                                                                                         |
| **save_on_each_node**                                 | `bool`                                                     | Yes          | `False`    | In multi-node distributed training, whether to save checkpoints on each node or only on the main one.                                                                                                                                                                                                                                                                                                                                                          |
| **save_only_model**                                   | `bool`                                                     | Yes          | `False`    | When checkpointing, save only the model, not the optimizer/scheduler/rng state. You can't resume training from such a checkpoint.                                                                                                                                                                                                                                                                                                                              |
| **restore_callback_states_from_checkpoint**           | `bool`                                                     | Yes          | `False`    | Whether to restore the callback states from the checkpoint. If `True`, will override callbacks passed to the `Trainer`.                                                                                                                                                                                                                                                                                                                                       |
| **use_cpu**                                           | `bool`                                                     | Yes          | `False`    | Whether or not to use CPU. If `False`, will use CUDA or MPS if available.                                                                                                                                                                                                                                                                                                                                                                                      |
| **seed**                                              | `int`                                                      | Yes          | `42`       | Random seed for training. Use `Trainer.model_init` if the model has random params to ensure reproducibility.                                                                                                                                                                                                                                                                                                                                                   |
| **data_seed**                                         | `int`                                                      | Yes          | -          | Random seed to be used with data samplers. Defaults to the same as `seed` if not set.                                                                                                                                                                                                                                                                                                                                                                          |
| **jit_mode_eval**                                     | `bool`                                                     | Yes          | `False`    | Whether or not to use PyTorch jit trace for inference.                                                                                                                                                                                                                                                                                                                                                                                                          |
| **use_ipex**                                          | `bool`                                                     | Yes          | `False`    | Use Intel extension for PyTorch when available.                                                                                                                                                                                                                                                                                                                                                                                                               |
| **bf16**                                              | `bool`                                                     | Yes          | `False`    | Whether to use bf16 16-bit mixed precision training instead of 32-bit training. Requires Ampere or higher GPU, CPU (use_cpu), or Ascend NPU.                                                                                                                                                                                                                                                                                                                   |
| **fp16**                                              | `bool`                                                     | Yes          | `False`    | Whether to use fp16 16-bit mixed precision training instead of 32-bit training.                                                                                                                                                                                                                                                                                                                                                                                |
| **fp16_opt_level**                                    | `str`                                                      | Yes          | `"O1"`     | Apex AMP optimization level for `fp16` training. Valid options: `"O0"`, `"O1"`, `"O2"`, `"O3"`.                                                                                                                                                                                                                                                                                                                                                                |
| **fp16_backend**                                      | `str`                                                      | Yes          | `"auto"`   | **Deprecated**. Use `half_precision_backend` instead.                                                                                                                                                                                                                                                                                                                                                                                                          |
| **half_precision_backend**                            | `str`                                                      | Yes          | `"auto"`   | The backend to use for mixed precision. `"auto"`, `"apex"`, `"cpu_amp"`.                                                                                                                                                                                                                                                                                                                                                                                       |
| **bf16_full_eval**                                    | `bool`                                                     | Yes          | `False`    | Whether to use full bfloat16 evaluation instead of 32-bit. Can be faster but may harm metric values.                                                                                                                                                                                                                                                                                                                                                           |
| **fp16_full_eval**                                    | `bool`                                                     | Yes          | `False`    | Whether to use full float16 evaluation instead of 32-bit. Can be faster but may harm metric values.                                                                                                                                                                                                                                                                                                                                                           |
| **tf32**                                              | `bool`                                                     | Yes          | -          | Whether to enable TF32 on Ampere or newer GPUs. Defaults to PyTorch's `torch.backends.cuda.matmul.allow_tf32`.                                                                                                                                                                                                                                                                                                                                                 |
| **local_rank**                                        | `int`                                                      | Yes          | `-1`       | Rank of the process during distributed training.                                                                                                                                                                                                                                                                                                                                                                                                                |
| **ddp_backend**                                       | `str`                                                      | Yes          | -          | The backend to use for distributed training: `"nccl"`, `"mpi"`, `"ccl"`, `"gloo"`, `"hccl"`.                                                                                                                                                                                                                                                                                                                                                                   |
| **tpu_num_cores**                                     | `int`                                                      | Yes          | -          | When training on TPU, the number of TPU cores. (Set automatically by launcher script.)                                                                                                                                                                                                                                                                                                                                                                          |
| **dataloader_drop_last**                              | `bool`                                                     | Yes          | `False`    | Whether to drop the last incomplete batch if dataset length is not divisible by the batch size.                                                                                                                                                                                                                                                                                                                                                                |
| **eval_steps**                                        | `int` or `float`                                           | Yes          | -          | Number of steps between evaluations if `eval_strategy="steps"`. Defaults to `logging_steps` if not set. Float < 1.0 => ratio of total steps.                                                                                                                                                                                                                                                                                                                   |
| **dataloader_num_workers**                            | `int`                                                      | Yes          | `0`        | Number of subprocesses for data loading (PyTorch only). 0 means loading in main process.                                                                                                                                                                                                                                                                                                                                                                       |
| **past_index**                                        | `int`                                                      | Yes          | `-1`       | For models like TransformerXL/XLNet that use "past" hidden states. If set, `Trainer` uses the output as `mems`.                                                                                                                                                                                                                                                                                                                                                 |
| **run_name**                                          | `str`                                                      | Yes          | `"output_dir"` | A descriptor for the run, used in logging integrations (wandb, mlflow, comet). Defaults to `output_dir`.                                                                                                                                                                                                                                                                                                                                                       |
| **disable_tqdm**                                      | `bool`                                                     | Yes          | -          | Whether or not to disable tqdm progress bars/metric tables in Jupyter. Defaults `True` if logging level <= warn, else `False`.                                                                                                                                                                                                                                                                                                                                 |
| **remove_unused_columns**                             | `bool`                                                     | Yes          | `True`     | Whether to automatically remove columns unused by the model forward method.                                                                                                                                                                                                                                                                                                                                                                                    |
| **label_names**                                       | `List[str]`                                               | Yes          | -          | The list of input keys that correspond to the labels. Defaults to any argument with "label" or special QA keys.                                                                                                                                                                                                                                                                                                                                                |
| **load_best_model_at_end**                            | `bool`                                                     | Yes          | `False`    | Whether or not to load the best model found during training at the end of training. Implies best checkpoint is always saved.                                                                                                                                                                                                                                                                                                                                   |
| **metric_for_best_model**                             | `str`                                                      | Yes          | -          | Metric to use with `load_best_model_at_end` for comparing two models. Must match a metric in evaluation output (like `"eval_loss"`).                                                                                                                                                                                                                                                                                                                           |
| **greater_is_better**                                 | `bool`                                                     | Yes          | -          | Use with `load_best_model_at_end` & `metric_for_best_model` to specify if a higher metric is better. Defaults based on whether metric ends with "loss".                                                                                                                                                                                                                                                                                                        |
| **ignore_data_skip**                                  | `bool`                                                     | Yes          | `False`    | When resuming training, whether or not to skip epochs/batches. If `True`, training starts faster but results differ from uninterrupted run.                                                                                                                                                                                                                                                                                                                     |
| **fsdp**                                              | `bool`, `str`, or `List[FSDPOption]`                       | Yes          | `""`       | Use PyTorch Fully Sharded Data Parallel (FSDP). Possible strings: `"full_shard"`, `"shard_grad_op"`, `"hybrid_shard"`, `"offload"`, `"auto_wrap"`, etc.                                                                                                                                                                                                                                                                                                        |
| **fsdp_config**                                       | `str` or `dict`                                            | Yes          | -          | FSDP config. Can be path to a json or a dict with FSDP settings like `min_num_params`, `transformer_layer_cls_to_wrap`, `backward_prefetch`, etc.                                                                                                                                                                                                                                                                                                             |
| **deepspeed**                                         | `str` or `dict`                                            | Yes          | -          | Use DeepSpeed (experimental). Value is either path to JSON config file or a dict. May enable Zero-init.                                                                                                                                                                                                                                                                                                                                                        |
| **accelerator_config**                                | `str`, `dict`, or `AcceleratorConfig`                      | Yes          | -          | Config for internal `Accelerator`. Either a JSON path, dict, or `AcceleratorConfig`. Options: `split_batches`, `dispatch_batches`, etc.                                                                                                                                                                                                                                                                                                                       |
| **label_smoothing_factor**                            | `float`                                                    | Yes          | `0.0`      | Label smoothing factor to use. 0 means no label smoothing.                                                                                                                                                                                                                                                                                                                                                                                                     |
| **debug**                                             | `str` or `List[DebugOption]`                               | Yes          | `""`       | Enable debug features. e.g. `"underflow_overflow"`, `"tpu_metrics_debug"`.                                                                                                                                                                                                                                                                                                                                                                                     |
| **optim**                                             | `str` or `OptimizerNames`                                  | Yes          | `"adamw_torch"` | The optimizer to use, e.g. `"adamw_hf"`, `"adamw_torch_fused"`, `"adafactor"`, etc.                                                                                                                                                                                                                                                                                                                                                                           |
| **optim_args**                                        | `str`                                                      | Yes          | -          | Optional arguments for certain optimizers (e.g. AnyPrecisionAdamW, AdEMAMix, GaLore).                                                                                                                                                                                                                                                                                                                                                                          |
| **group_by_length**                                   | `bool`                                                     | Yes          | `False`    | Whether or not to group samples of similar lengths to minimize padding. Only useful if applying dynamic padding.                                                                                                                                                                                                                                                                                                                                               |
| **length_column_name**                                | `str`                                                      | Yes          | `"length"` | Column name for precomputed lengths (used if `group_by_length` is True and dataset is a `Dataset`).                                                                                                                                                                                                                                                                                                                                                             |
| **report_to**                                         | `str` or `List[str]`                                       | Yes          | `"all"`    | Integrations to report results/logs to: `"azure_ml"`, `"tensorboard"`, `"wandb"`, `"mlflow"`, etc. `"all"` or `"none"`.                                                                                                                                                                                                                                                                                                                                        |
| **ddp_find_unused_parameters**                        | `bool`                                                     | Yes          | -          | For distributed training, passed to `DistributedDataParallel` as `find_unused_parameters`. Defaults `False` if gradient checkpointing is used.                                                                                                                                                                                                                                                                                                                |
| **ddp_bucket_cap_mb**                                 | `int`                                                      | Yes          | -          | For distributed training, passed to `DistributedDataParallel` as `bucket_cap_mb`.                                                                                                                                                                                                                                                                                                                                                                             |
| **ddp_broadcast_buffers**                             | `bool`                                                     | Yes          | -          | Passed to `DistributedDataParallel` as `broadcast_buffers`. Defaults `False` if gradient checkpointing is used, else `True`.                                                                                                                                                                                                                                                                                                                                   |
| **dataloader_pin_memory**                             | `bool`                                                     | Yes          | `True`     | Whether you want to pin memory in data loaders.                                                                                                                                                                                                                                                                                                                                                                                                               |
| **dataloader_persistent_workers**                     | `bool`                                                     | Yes          | `False`    | If `True`, workers don't shut down after one dataset consumption. Speeds up training but increases RAM usage.                                                                                                                                                                                                                                                                                                                                                  |
| **dataloader_prefetch_factor**                        | `int`                                                      | Yes          | -          | Number of batches loaded in advance by each worker.                                                                                                                                                                                                                                                                                                                                                                                                            |
| **skip_memory_metrics**                               | `bool`                                                     | Yes          | `True`     | Whether to skip memory profiler reports. Skipped by default to speed up training/evaluation.                                                                                                                                                                                                                                                                                                                                                                   |
| **push_to_hub**                                       | `bool`                                                     | Yes          | `False`    | Whether or not to push the model to the Hub every time the model is saved. Requires a git repo in `output_dir`.                                                                                                                                                                                                                                                                                                                                                |
| **resume_from_checkpoint**                            | `str`                                                      | Yes          | -          | Path to a folder with a valid checkpoint. Not used directly by `Trainer`; used by training/eval scripts.                                                                                                                                                                                                                                                                                                                                                       |
| **hub_model_id**                                      | `str`                                                      | Yes          | -          | Repo name to keep in sync with local `output_dir`. Defaults to `"user_name/output_dir_name"`.                                                                                                                                                                                                                                                                                                                                                                  |
| **hub_strategy**                                      | `str` or `HubStrategy`                                     | Yes          | `"every_save"` | Scope of what/when is pushed to the Hub: `"end"`, `"every_save"`, `"checkpoint"`, `"all_checkpoints"`.                                                                                                                                                                                                                                                                                                                                                        |
| **hub_token**                                         | `str`                                                      | Yes          | -          | Token to push model to the Hub. Defaults to the one from `huggingface-cli login`.                                                                                                                                                                                                                                                                                                                                                                              |
| **hub_private_repo**                                  | `bool`                                                     | Yes          | -          | Whether to make the repo private (if creating a new one). Ignored if the repo already exists.                                                                                                                                                                                                                                                                                                                                                                  |
| **hub_always_push**                                   | `bool`                                                     | Yes          | `False`    | If not `True`, skip pushing a checkpoint when the previous push isn't finished.                                                                                                                                                                                                                                                                                                                                                                                |
| **gradient_checkpointing**                            | `bool`                                                     | Yes          | `False`    | If `True`, use gradient checkpointing to save memory at the expense of slower backward pass.                                                                                                                                                                                                                                                                                                                                                                   |
| **gradient_checkpointing_kwargs**                     | `dict`                                                     | Yes          | `None`     | Key-value arguments passed to the `gradient_checkpointing_enable` method.                                                                                                                                                                                                                                                                                                                                                                                      |
| **include_inputs_for_metrics**                        | `bool`                                                     | Yes          | `False`    | **Deprecated**. Use `include_for_metrics` instead.                                                                                                                                                                                                                                                                                                                                                                                                             |
| **include_for_metrics**                               | `List[str]`                                               | Yes          | `[]`       | Which additional data to provide to `compute_metrics`. Possible: `"inputs"`, `"loss"`.                                                                                                                                                                                                                                                                                                                                                                         |
| **eval_do_concat_batches**                            | `bool`                                                     | Yes          | `True`     | Whether to recursively concat inputs/losses/labels/preds across batches. If `False`, store them as lists.                                                                                                                                                                                                                                                                                                                                                      |
| **auto_find_batch_size**                              | `bool`                                                     | Yes          | `False`    | Whether to find a batch size that fits into memory automatically through exponential decay, avoiding OOM errors.                                                                                                                                                                                                                                                                                                                                               |
| **full_determinism**                                  | `bool`                                                     | Yes          | `False`    | If `True`, uses `enable_full_determinism` for reproducible results in distributed training. Slower performance.                                                                                                                                                                                                                                                                                                                                                |
| **torchdynamo**                                       | `str`                                                      | Yes          | -          | The backend compiler for TorchDynamo. e.g. `"eager"`, `"aot_eager"`, `"inductor"`, etc.                                                                                                                                                                                                                                                                                                                                                                        |
| **ray_scope**                                         | `str`                                                      | Yes          | `"last"`   | Scope to use when doing hyperparameter search with Ray. `"last"` uses the last checkpoint of all trials.                                                                                                                                                                                                                                                                                                                                                       |
| **ddp_timeout**                                       | `int`                                                      | Yes          | `1800`     | Timeout (in seconds) for `torch.distributed.init_process_group`. Prevents GPU socket timeouts.                                                                                                                                                                                                                                                                                                                                                                  |
| **use_mps_device**                                    | `bool`                                                     | Yes          | `False`    | **Deprecated**. MPS device is used automatically if available, similar to CUDA.                                                                                                                                                                                                                                                                                                                                                                                |
| **torch_compile**                                     | `bool`                                                     | Yes          | `False`    | Whether to compile the model using PyTorch 2.0 `torch.compile`. Experimental.                                                                                                                                                                                                                                                                                                                                                                                  |
| **torch_compile_backend**                             | `str`                                                      | Yes          | -          | The backend to use in `torch.compile`. Setting this forces `torch_compile=True`. Experimental.                                                                                                                                                                                                                                                                                                                                                                  |
| **torch_compile_mode**                                | `str`                                                      | Yes          | -          | The mode to use in `torch.compile`. Setting this forces `torch_compile=True`. Experimental.                                                                                                                                                                                                                                                                                                                                                                     |
| **split_batches**                                     | `bool`                                                     | Yes          | -          | Whether the accelerator splits batches across devices. Must be a multiple of num_processes if `True`.                                                                                                                                                                                                                                                                                                                                                          |
| **include_tokens_per_second**                         | `bool`                                                     | Yes          | -          | Whether to compute tokens/sec per device for training speed metrics. Iterates once over the entire training dataloader.                                                                                                                                                                                                                                                                                                                                        |
| **include_num_input_tokens_seen**                     | `bool`                                                     | Yes          | -          | Whether to track number of input tokens seen throughout training. May be slower in distributed.                                                                                                                                                                                                                                                                                                                                                                |
| **neftune_noise_alpha**                               | `float`                                                    | Yes          | -          | If not `None`, activates NEFTune noise embeddings for instruction fine-tuning. Range `[5.0, 15.0]` used in paper.                                                                                                                                                                                                                                                                                                                                              |
| **optim_target_modules**                              | `str` or `List[str]`                                       | Yes          | -          | Target modules to optimize (module names) for certain optimizers like GaLore. Must be `nn.Linear` modules only.                                                                                                                                                                                                                                                                                                                                                |
| **batch_eval_metrics**                                | `bool`                                                     | Yes          | `False`    | If `True`, `compute_metrics` is called at the end of each batch to accumulate stats. Requires `compute_metrics` to accept a `compute_result` argument.                                                                                                                                                                                                                                                                                                          |
| **eval_on_start**                                     | `bool`                                                     | Yes          | `False`    | Whether to perform an evaluation step before training (sanity check).                                                                                                                                                                                                                                                                                                                                                                                          |
| **eval_use_gather_object**                            | `bool`                                                     | Yes          | `False`    | Whether to run recursively gather object in a nested list/tuple/dict from all devices. Only enable if returning non-tensors.                                                                                                                                                                                                                                                                                                                                   |
| **use_liger_kernel**                                  | `bool`                                                     | Yes          | `False`    | Whether to enable [Liger](https://github.com/linkedin/Liger-Kernel) Kernel for LLM training. Can improve multi-GPU throughput and reduce memory usage. |
